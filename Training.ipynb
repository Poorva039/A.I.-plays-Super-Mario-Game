{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37d63118",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f9b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym \n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, RIGHT_ONLY \n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gym_utils import SMBRamWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3dac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3` with the environment ID `SuperMarioBros-1-1-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec773972",
   "metadata": {},
   "source": [
    "# 2. Process Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdffe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cropping size\n",
    "x0 = 0\n",
    "x1 = 16\n",
    "y0 = 0\n",
    "y1 = 13\n",
    "n_stack = 4\n",
    "n_skip = 4\n",
    "\n",
    "env_wrap = SMBRamWrapper(env, [x0, x1, y0, y1], n_stack=n_stack, n_skip=n_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1018d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test env_wrap\n",
    "done = True\n",
    "for i in range(150):\n",
    "    if done:\n",
    "        state = env_wrap.reset()\n",
    "    state, reward, done, info = env_wrap.step(env_wrap.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be737c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 16, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503a7d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, n_stack, figsize=(14,10))\n",
    "for i in range(n_stack):\n",
    "    ax[i].imshow(state[:,:,n_stack-i-1], vmin=-1, vmax=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc903d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.render_mode to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.render_mode` for environment variables or `env.get_wrapper_attr('render_mode')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:74: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    }
   ],
   "source": [
    "# Apply other wrapper functions\n",
    "env_wrap = Monitor(env_wrap)  # for tensorboard log\n",
    "env_wrap = DummyVecEnv([lambda: env_wrap])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1f4a86f",
   "metadata": {},
   "source": [
    "# 3. Setup RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09f25b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "# Save intermediate models\n",
    "# Copied from Nicholas Renotte's code\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, \n",
    "                 starting_steps=0, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.starting_steps = starting_steps\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls + int(self.starting_steps)))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "# Linear learning rate schedule\n",
    "# https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#learning-rate-schedule\n",
    "from typing import Callable\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20a1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFY THESE TWO DIRECTORIES BEFORE TRAINING A NEW MODEL ###\n",
    "MODEL_DIR = './models/NEW_MODEL_DIR'\n",
    "LOG_DIR = './logs/NEW_LOG_DIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9d9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The algorithm only supports (<class 'gymnasium.spaces.box.Box'>, <class 'gymnasium.spaces.discrete.Discrete'>, <class 'gymnasium.spaces.multi_discrete.MultiDiscrete'>, <class 'gymnasium.spaces.multi_binary.MultiBinary'>) as action spaces but Discrete(7) was provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m PPO(\u001b[39m'\u001b[39;49m\u001b[39mMlpPolicy\u001b[39;49m\u001b[39m'\u001b[39;49m, env_wrap, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49mlinear_schedule(\u001b[39m3e-4\u001b[39;49m), tensorboard_log\u001b[39m=\u001b[39;49mLOG_DIR) \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:104\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     79\u001b[0m     policy: Union[\u001b[39mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _init_setup_model: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    103\u001b[0m ):\n\u001b[0;32m--> 104\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    105\u001b[0m         policy,\n\u001b[1;32m    106\u001b[0m         env,\n\u001b[1;32m    107\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    108\u001b[0m         n_steps\u001b[39m=\u001b[39;49mn_steps,\n\u001b[1;32m    109\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    110\u001b[0m         gae_lambda\u001b[39m=\u001b[39;49mgae_lambda,\n\u001b[1;32m    111\u001b[0m         ent_coef\u001b[39m=\u001b[39;49ment_coef,\n\u001b[1;32m    112\u001b[0m         vf_coef\u001b[39m=\u001b[39;49mvf_coef,\n\u001b[1;32m    113\u001b[0m         max_grad_norm\u001b[39m=\u001b[39;49mmax_grad_norm,\n\u001b[1;32m    114\u001b[0m         use_sde\u001b[39m=\u001b[39;49muse_sde,\n\u001b[1;32m    115\u001b[0m         sde_sample_freq\u001b[39m=\u001b[39;49msde_sample_freq,\n\u001b[1;32m    116\u001b[0m         stats_window_size\u001b[39m=\u001b[39;49mstats_window_size,\n\u001b[1;32m    117\u001b[0m         tensorboard_log\u001b[39m=\u001b[39;49mtensorboard_log,\n\u001b[1;32m    118\u001b[0m         policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs,\n\u001b[1;32m    119\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    120\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    121\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    122\u001b[0m         _init_setup_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    123\u001b[0m         supported_action_spaces\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    124\u001b[0m             spaces\u001b[39m.\u001b[39;49mBox,\n\u001b[1;32m    125\u001b[0m             spaces\u001b[39m.\u001b[39;49mDiscrete,\n\u001b[1;32m    126\u001b[0m             spaces\u001b[39m.\u001b[39;49mMultiDiscrete,\n\u001b[1;32m    127\u001b[0m             spaces\u001b[39m.\u001b[39;49mMultiBinary,\n\u001b[1;32m    128\u001b[0m         ),\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    131\u001b[0m     \u001b[39m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39m# because of the advantage normalization\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m normalize_advantage:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:81\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     60\u001b[0m     policy: Union[\u001b[39mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[39m.\u001b[39mSpace], \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     82\u001b[0m         policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[1;32m     83\u001b[0m         env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m     84\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     85\u001b[0m         policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs,\n\u001b[1;32m     86\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     87\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     88\u001b[0m         use_sde\u001b[39m=\u001b[39;49muse_sde,\n\u001b[1;32m     89\u001b[0m         sde_sample_freq\u001b[39m=\u001b[39;49msde_sample_freq,\n\u001b[1;32m     90\u001b[0m         support_multi_env\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     91\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m     92\u001b[0m         stats_window_size\u001b[39m=\u001b[39;49mstats_window_size,\n\u001b[1;32m     93\u001b[0m         tensorboard_log\u001b[39m=\u001b[39;49mtensorboard_log,\n\u001b[1;32m     94\u001b[0m         supported_action_spaces\u001b[39m=\u001b[39;49msupported_action_spaces,\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps \u001b[39m=\u001b[39m n_steps\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m=\u001b[39m gamma\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:180\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vec_normalize_env \u001b[39m=\u001b[39m unwrap_vec_normalize(env)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m supported_action_spaces \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, supported_action_spaces), (\n\u001b[1;32m    181\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe algorithm only supports \u001b[39m\u001b[39m{\u001b[39;00msupported_action_spaces\u001b[39m}\u001b[39;00m\u001b[39m as action spaces \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m}\u001b[39;00m\u001b[39m was provided\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m support_multi_env \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_envs \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError: the model does not support multiple envs; it requires \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma single vectorized environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: The algorithm only supports (<class 'gymnasium.spaces.box.Box'>, <class 'gymnasium.spaces.discrete.Discrete'>, <class 'gymnasium.spaces.multi_discrete.MultiDiscrete'>, <class 'gymnasium.spaces.multi_binary.MultiBinary'>) as action spaces but Discrete(7) was provided"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env_wrap, verbose=1, learning_rate=linear_schedule(3e-4), tensorboard_log=LOG_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1e5, starting_steps=0, save_path=MODEL_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e212fb30",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b8e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "model.learn(total_timesteps=10e6, callback=callback)\n",
    "\n",
    "t_elapsed = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Wall time: {} s'.format(round(t_elapsed, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be236c1b",
   "metadata": {},
   "source": [
    "# Save and load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ef893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = os.path.join(MODEL_DIR, 'SAVED_MODEL_NAME')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd36cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "MODEL_DIR = './models/SAVED_MODEL_NAME'\n",
    "LOG_DIR = './logs/SAVED_LOG_DIR'\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, 'SAVED_MODEL_NAME')\n",
    "model = PPO.load(model_path, env=env_wrap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d15d11ab",
   "metadata": {},
   "source": [
    "# Open tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b606aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_NAME = 'PPO_5'\n",
    "TB_LOG = os.path.join(LOG_DIR, LOG_NAME)\n",
    "\n",
    "!tensorboard --logdir={TB_LOG}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "830f39a6",
   "metadata": {},
   "source": [
    "# 4. Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env_wrap, n_eval_episodes=1, deterministic=True, render=False, return_episode_rewards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 1\n",
    "\n",
    "for episode in range(1, episode+1):\n",
    "    states = env_wrap.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env_wrap.render()\n",
    "        action, _ = model.predict(states, deterministic=True)\n",
    "        states, reward, done, info = env_wrap.step(action)\n",
    "        score += reward\n",
    "        time.sleep(0.01)\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "#env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
